{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On-Device, Real-Time Hand Tracking with MediaPipe\n",
    "( https://ai.googleblog.com/2019/08/on-device-real-time-hand-tracking-with.html )\n",
    "\n",
    "1. 專案的目標？ (要解決什麼問題）\n",
    "為了實現创造性用例的出现，刺激新的应用和新的研究途径。\n",
    "\n",
    "2. 使用的技術是？ (只需知道名稱即可，例如：使用 CNN 卷積神經網路做影像分類)\n",
    "BlazePalm:初始的時候，偵測手掌.\n",
    "Hand Landmark Model:給予手掌骨架.\n",
    "文章中提到單純的合成數據很難推廣到野,所以利用mixed training schema來達到野外辨識效果.\n",
    "Gesture Recognition:辨識及輸出結果.\n",
    "\n",
    "3. 資料來源？ \n",
    "Post by Valentin Bazarevsky and Fan Zhang, Research Engineers, Google Research"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
